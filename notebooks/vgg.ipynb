{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.utils.data as data\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 128\n",
    "learning_rate = 1e-5\n",
    "valid_ratio = .25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensor_files = os.listdir('/mnt/sde1/neuralMusic/data/spectrogram_tensors/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(tensor_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/mnt/sde1/neuralMusic/data/tensor_genres.csv', dtype=object)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def filter_tensor_files(tensor_path, tensor_file):\n",
    "#     tensor = np.fromfile(tensor_path + tensor_file)\n",
    "#     tensor = torch.from_numpy(tensor)\n",
    "#     tensor = tensor.view(-1, 512)\n",
    "#     if tensor.shape[0] != 512 or tensor.shape[1] != 512:\n",
    "#         return(False)\n",
    "#     else:\n",
    "#         return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FmaDataset(data.Dataset):\n",
    "    \"\"\"Dataset wrapping Free Music Archive Spectrogram Tensors.\n",
    "    Arguments:\n",
    "        A CSV file path with the tensors, labels\n",
    "        Path to tensor folder\n",
    "        Extension of images\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_path, tensor_path, transform=None):\n",
    "        tmp_df = pd.read_csv(csv_path, dtype=object)\n",
    "        tmp_df2 = tmp_df[tmp_df['tensor_name'].apply(lambda x: np.fromfile(tensor_path + x).size==262144)]  \n",
    "        assert tmp_df2['tensor_name'].apply(lambda x: os.path.isfile(tensor_path + x)).all(), \\\n",
    "\"Some tensors referenced in the CSV file were not found\"\n",
    "        assert tmp_df2['tensor_name'].apply(lambda x: np.fromfile(tensor_path + x).size==262144).all(), \\\n",
    "\"Some tensors referenced had the wrong number of elements\"\n",
    "        tmp_df2 = tmp_df2.reset_index(drop=True)\n",
    "        tmp_df2 = tmp_df2[:7552]\n",
    "        \n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.tensor_path = tensor_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.X_train = tmp_df2['tensor_name']\n",
    "        self.y_train = self.mlb.fit_transform(tmp_df2['genre_top'].str.split()).astype(np.float32)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        tensor = np.fromfile(self.tensor_path + self.X_train[index])\n",
    "        tensor = torch.from_numpy(tensor)\n",
    "        tensor = tensor.view(512, 512)\n",
    "        tensor = tensor.unsqueeze(0).float()\n",
    "        if self.transform is not None:\n",
    "            tensor = self.transform(tensor)\n",
    "            \n",
    "        label = self.y_train[index].argmax(axis=0)\n",
    "        return tensor, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = FmaDataset(csv_path='/mnt/sde1/neuralMusic/data/tensor_genres.csv', tensor_path='/home/cblythe2/github/neuralMusic/data/spectrogram_tensors/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = torch.randperm(len(dataset))\n",
    "valid_size = int(len(dataset) * valid_ratio)\n",
    "train_indices = indices[:len(indices)-valid_size]\n",
    "valid_indices = indices[len(indices)-valid_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fma_dataset.X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fma_dataset.y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fma_dataset.y_train[75:83]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fma_dataset.X_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(dataset,\n",
    "                          batch_size=batch_size, sampler=data.sampler.SubsetRandomSampler(train_indices),\n",
    "                          num_workers=1\n",
    "                          # pin_memory =True # CUDA only\n",
    "                         )\n",
    "\n",
    "valid_loader = data.DataLoader(dataset, sampler=data.sampler.SubsetRandomSampler(valid_indices),\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=1\n",
    "                          # pin_memory =True # CUDA only\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network ~ 45.7% Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN Model (2 conv layer)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "#         self.fc = nn.Linear(128*32*32, 8)\n",
    "        self.fc = nn.Linear(256*16*16, 8)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN (\n",
       "  (layer1): Sequential (\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "    (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (layer2): Sequential (\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "    (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (layer3): Sequential (\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "    (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (layer4): Sequential (\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "    (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (layer5): Sequential (\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "    (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (fc): Linear (65536 -> 8)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for i, (tensors, labels) in enumerate(train_loader):\n",
    "        tensors = Variable(tensors).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(tensors)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return(loss.data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(best_accuracy):\n",
    "    my_labels = []\n",
    "    my_predictions = []\n",
    "    model.eval()    # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for tensors, labels in valid_loader:\n",
    "        tensors = Variable(tensors, volatile=True).cuda()\n",
    "        outputs = model(tensors)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.cpu() == labels).sum()\n",
    "        my_labels += labels.tolist()\n",
    "        my_predictions += predicted.cpu().tolist()\n",
    "    epoch_accuracy = (100 * correct / total)\n",
    "    return(epoch_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Hyperparameters------\n",
      "Number of Epochs | 1\n",
      "Batch Size       | 128\n",
      "LR:              | 0.00001\n",
      "Validation Ratio | 0.250\n",
      "\n",
      "---------------------------\n",
      "Training on 5664 examples\n",
      "Testing on 1888 examples\n",
      "---------------------------\n",
      "\n",
      "CNN (\n",
      "  (layer1): Sequential (\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU ()\n",
      "    (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (layer2): Sequential (\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU ()\n",
      "    (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (layer3): Sequential (\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU ()\n",
      "    (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (layer4): Sequential (\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU ()\n",
      "    (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (layer5): Sequential (\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU ()\n",
      "    (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (fc): Linear (65536 -> 8)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "Epoch [0/1] Training Loss: 1.8696\n",
      "Epoch [0/1] Validation Accuracy: 23.68\n",
      "\n",
      "Best Validation Accuracy of 23.68% at Epoch 0 of 1 in 0.6 minutes\n"
     ]
    }
   ],
   "source": [
    "best_epoch = 0\n",
    "best_accuracy = 0\n",
    "print('------Hyperparameters------\\nNumber of Epochs | {:.0f}\\nBatch Size       | {:.0f}\\nLR:              | {:.5f}\\nValidation Ratio | {:.3f}\\n'.format(num_epochs, batch_size, learning_rate, valid_ratio))\n",
    "print(\"---------------------------\\nTraining on {} examples\\nTesting on {} examples\\n---------------------------\\n\".format(len(train_indices), len(valid_indices)))\n",
    "print(model)\n",
    "print('\\n\\n')\n",
    "begin_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    try:\n",
    "        # Train model over epoch\n",
    "        loss_data = train(epoch)\n",
    "        print('Epoch [%d/%d] Training Loss: %.4f' % (epoch, num_epochs, loss_data))\n",
    "        # Test the Model at end of every epoch\n",
    "        valid_accuracy = test(epoch)\n",
    "        print(\"Epoch [%d/%d] Validation Accuracy: %.2f\" % (epoch, num_epochs, valid_accuracy))\n",
    "        if valid_accuracy > best_accuracy:\n",
    "            best_accuracy = valid_accuracy\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), 'best_model.pkl')\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nBest Validation Accuracy of {:.2f}% at Epoch {:.0f}\".format(best_accuracy, best_epoch))\n",
    "        sys.exit(1)\n",
    "print(\"\\nBest Validation Accuracy of {:.2f}% at Epoch {:.0f} of {:.0f} in {:.1f} minutes\".format(best_accuracy, best_epoch, num_epochs, int((time.time() - begin_time))/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
